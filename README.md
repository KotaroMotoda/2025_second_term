# 2025年度前期 - こんちゃテスト6章

## 1. ソフトウェアの並列性

### 逐次プログラム
- **単位**: プログラム全体

### 並列プログラム

#### タスク並列 `[単位: タスク/プロセス]`
複数の独立したタスク（プロセスやスレッド）を同時に実行する方式。各タスクは異なる処理内容を持つことが多く、ワークフローや分散処理などで利用される。スレッド並列よりも粒度が粗い.

**例**: Webサーバのリクエスト処理、分散シミュレーション

#### スレッド並列 `[単位: スレッド]`
一つのプログラム内で複数のスレッドが同時に動作し、同じ処理や異なる処理を分担して実行する方式。主に共有メモリ上で動作し、マルチコアCPU(1つのCPUに複数の独立した演算ユニットを持つCPU)での高速化に利用される。タスク並列よりも,粒度が細かい.

> **ソフトウェアでの実装例**：
> - **pthread**: C言語でのスレッド作成・管理
> - **OpenMP**: `#pragma omp parallel` でループの並列化
> - **Java Thread**: `new Thread(() -> { 処理 }).start()`
> - **Python threading**: `threading.Thread(target=関数).start()`

**例**: マルチスレッドプログラム、並列ソート

#### タスク並列 `[単位: タスク/プロセス]`
複数の独立したタスク（プロセスやスレッド）を同時に実行する方式。各タスクは異なる処理内容を持つことが多く、ワークフローや分散処理などで利用される。スレッド並列よりも粒度が粗い.

> **ソフトウェアでの実装例**：
> - **プロセス生成**: `fork()`, `exec()`でプロセスを分岐
> - **非同期処理**: `async/await`, Promise, Future
> - **ワーカープール**: タスクキューに処理を投入
> - **マイクロサービス**: 独立したサービス間での処理分散

**例**: Webサーバのリクエスト処理、分散シミュレーション


#### データ並列 `[単位: データ要素]`
同じ処理を大量のデータ要素に対して同時に適用する方式。ベクトル演算や画像処理、科学技術計算などでよく使われる。

> **補足：ソフトウェアとハードウェアのデータ並列性の違い**
> - ソフトウェアでfor文などを使って「同じ処理を大量のデータに適用する」ことは、あくまで“並列にできる性質”を持つだけで、実際に並列実行されるとは限りません（多くの場合は逐次実行）。
> - NumPyやGPU対応ライブラリのように「並列実行したい」という意図を持ったソフトウェアを使うと、並列実行の“要求”が生まれますが、この時点でもまだ並列実行は確定ではありません。
> - 実際に並列実行されるかどうかは、下層のハードウェア（CPUやGPU）がSIMDやベクトルアーキテクチャなどの並列実行機能を持っているかどうかに依存します。
> - ハードウェアがスカラアーキテクチャなら逐次実行、SIMDやベクトルアーキテクチャなら本当に並列実行されます。
> - つまり「ソフトウェアが並列性を持つ処理を書き」「ハードウェアがそれを活かせる機能を持っている」ときに、はじめて“実際の並列実行”が実現します。

**例**: 行列演算、GPUによる画像フィルタ処理

---

## レイヤ間対応関係

### ソフトウェア並列性 → プログラミングモデル → ハードウェア実装

| **ソフトウェア並列性**<br/>（第1章） | **プログラミングモデル**<br/>（第2章） | **ハードウェア実装**<br/>（第3章） | **実際のプロダクト例** |
|---|---|---|---|
| **データ並列**<br/>・同じ処理を大量のデータ要素に対して同時に適用<br/>・行列演算、GPUによる画像フィルタ処理 | **SIMD**<br/>・単一命令、複数データ<br/>・ベクトル(一次元配列)を操作 | **SIMDプロセッサ(GPUはMIMD)**<br/>・単一命令で複数データを同時処理<br/>**ベクトルプロセッサ**<br/>・ベクトル命令で長いデータ列を同時処理 | ・行列演算<br/>・GPUによる画像フィルタ処理(最近MIMD化してる) |
| **スレッド並列**<br/>・一つのプログラム内で複数スレッドが同時動作<br/>・マルチスレッドプログラム、並列ソート | **MIMD**<br/>・複数命令、複数データ | **マルチコア**<br/>・複数コアで同時に命令を実行<br/>**SMP/NUMA**<br/>・複数プロセッサ/ノードによる並列 | ・マルチスレッドプログラム<br/>・並列ソート |
| **タスク並列**<br/>・複数の独立したタスクを同時実行<br/>・Webサーバのリクエスト処理、分散シミュレーション | **MIMD + メッセージパッシング**<br/>・ネットワークを介してメッセージを交換.<br/>・各プロセッサが固有のアドレス空間 | **クラスタ（疎結合）**<br/>・独立したコンピュータを複数台ネット接続<br/>**グリッドコンピューティング**<br/>・PCを広域に分散 | ・Webサーバのリクエスト処理<br/>・分散シミュレーション |
| **パイプライン処理**<br/>・命令を段階的に重ねて実行 | **MISD**<br/>・複数命令、単一データ<br/>・パイプライン方式で一連の計算を実行 | **パイプライン**<br/>・命令を段階的に重ねて実行 | ・CPU命令処理<br/>・時間的並列処理 |

### 重要なポイント
- **ソフトウェア**: プログラマーが書く並列性の表現方法
- **プログラミングモデル**: 抽象的な実行方式の分類（理論的枠組み）
- **ハードウェア**: 実際に並列実行を行う物理的な仕組み
- **プロダクト**: 最終的に生まれるアプリケーションやシステム

### レイヤ間の関係性

**ソフトウェア（コード）** ↔ **プログラミングモデル（コンパイラ・実行環境）** ↔ **ハードウェア（アーキテクチャ）**

> **プログラミングモデルの実体**：
> 
> **1. コンパイラレベルでの変換**：
> ```c
> // ソフトウェア（プログラマーが書くコード）
> for(int i = 0; i < 1000; i++) {
>     result[i] = a[i] + b[i];  // データ並列性を表現
> }
> 
> // ↓ コンパイラが変換（プログラミングモデル = SIMD）
> 
> // ハードウェア（実際に実行される命令）
> __m128 va = _mm_load_ps(a);     // SIMD命令：4要素同時ロード
> __m128 vb = _mm_load_ps(b);     // SIMD命令：4要素同時ロード
> __m128 vr = _mm_add_ps(va, vb); // SIMD命令：4要素同時加算
> _mm_store_ps(result, vr);       // SIMD命令：4要素同時保存
> ```
> 
> **2. 実行環境・ランタイムレベルでの最適化**：
> - **NumPy**: 内部でBLAS（Basic Linear Algebra Subprograms）経由でSIMD活用
> - **OpenMP**: `#pragma omp parallel` → スレッド生成・管理
> - **GPU実行環境**: CUDA/OpenCL → 大量並列実行
> - **JIT（Just-In-Time）コンパイラ**: 実行時にハードウェアに合わせて最適化
> 
> **つまり**：プログラミングモデルとは、**コンパイラ・実行環境が持つ変換ポリシー**のこと

---

## 2. プログラミングモデル・分類軸

### Flynnの分類 `[単位: 命令流/データ流]`
- **SISD**: 単一命令、単一データ
- **SIMD**: 単一命令、複数データ. 
  - **仕組み**: 単一のプログラムカウンタが指示する1つの命令に対して、複数の並列実行ユニット（ALU）が同期して同じ演算を異なるデータに対して実行する
  - **用途**: ベクトル(一次元配列)の要素に対する同一処理など、データ並列性を活用
  - **体験**: ユーザからはSISD命令実行と同じ体験（プログラムカウンタは1つ）だが、内部では複数データが並列処理される
  - **データ並列性がなくても...**: アウトオブオーダーや,スーパースカラを用いて,同スレッド内で「依存しない複数の命令」を同時に実行したり,実行を先に持ってきたりして演算機の空きを減らして高速化できる.
- **MISD**: 複数命令、単一データ. 
  - **仕組み**: 単一のデータ流に対して、複数の処理ステップ（命令）が段階的に適用される。各ステップは異なる演算ユニットで並列実行される
  - **用途**: パイプライン処理、フォルトトレラント（冗長）システム、信号処理チェーンなど
  - **体験**: 同じデータに対して複数の異なる処理や検証を並列で行い、結果を統合・比較する
- **MIMD**: 複数命令、複数データ. 通常のマルチコアプロセッサで使われるのはこれ.

### その他の分類
- **SPMD/MPMD**: 単一/複数プログラム
- **メッセージパッシング** `[単位: プロセス間通信]`: 共有メモリへのアクセスはmsで,クロック周期はnsなので,メモリにアクセスするたびに数千クロックかかる.これは馬鹿らしい.共有メモリに代わり,*各プロセッサが固有のアドレス空間(高速にアクセス可能)を持つシステムが必要*となった時に,ネットワークを介してメッセージを交換(メッセージパッシング)を用いればそれが実装できるじゃんということで実装された. 課題は以下の3つである.
  - ***ハードウェア*** : ネットワークが大事なので,ここにコストかかる.
  - ***ソフトウェア*** : 明示的に情報交換を記述する必要がある.既存のappを,メッセージパッシング方式に変更する時に莫大なコストがかかる.
  - ***性能の見積もり,チューニングの課題***

---
## 3. ハードウェア並列性

### 並列性の階層的分類

| 並列性レベル         | 主な実装例                    | 説明・特徴                                 |
|----------------------|--------------------------------|--------------------------------------------|
| プロセッサレベル     | ・マルチコア<br/>・SMP/NUMA<br/>・クラスタ<br/>・グリッド | ・マルチコア: 1つのチップに複数の独立したCPUコアを搭載し、各コアが独立して命令実行。共有キャッシュで連携<br/>・SMP：複数CPU間で共有メモリを使用。均等なメモリアクセス時間<br/>・NUMA：CPUごとにローカルメモリを持ち、アクセス時間が不均等<br/>・クラスタ：独立したマシンをネットワーク接続。メッセージパッシングで通信. 要求レベル並列の実現.<br/>・グリッド：地理的に分散配置されたマシン群による大規模分散処理 |
| スレッドレベル       | ・SMT<br/>・粗粒度MT<br/>・細粒度MT | ・SMT：1コアで複数スレッドを同時実行。スーパースカラが前提となる.スーパースカラは,単一データ流の命令をパイプラインに入れて同時実行していくが,同じスレッド内の命令では命令依存が多く,パイプラインを全て埋めるのは難しかった.しかし,SMTは複数スレッドを扱うので,依存のないスレッドを跨ぐ命令をパイプラインに入れることで,スーパースカラは最高のコスパで動ける.(スレッドレベル並列性と命令レベル並列性の両立)<br/>・粗粒度MT：メモリ待ちなど長期ストール時のみスレッド切替<br/>・細粒度MT：命令ごとにスレッド切替。きめ細かい時分割実行 |
| 命令レベル（ILP）    | ・パイプライン<br/>・スーパースカラ<br/>・VLIW | ・パイプライン：命令を複数段階に分けて各段階を並列実行。スループット向上<br/>・スーパースカラ：複数のパイプラインを持ち,そこに複数の命令が読み込まれて同時に実行されていく.つまり,複数命令発行でき,複数命令同時実行可能ということ.しかし,単一のスレッド内の命令を実行するため,命令間の依存が多く,パイプラインを全て埋めるのは厳しい.(SMTは別.)<br/>・VLIW：コンパイル時に並列性を抽出し、長い命令語で明示的に並列実行を指定 |
| データレベル（DLP）  | ・SIMDプロセッサ<br/>・ベクトルプロセッサ<br/>・GPU | ・SIMD：128/256/512bit等の固定長データを一括処理。プログラマがデータ長を意識<br/>・ベクトル：可変長のデータ列を自動分割して処理。連続アクセスで効率的<br/>・GPU：数千の演算コアによる大規模並列処理.とんでもない数のコアをグループ化してそれらが新しく命令出せるので,GPUはMIMD化している.レイテンシは,スレッドの切り替えで隠せるので,多数の演算器に十分なデータを供給できるようにメモリバンド幅を大きくするのに注力している. |
| スカラ               | ・スカラアーキテクチャ | ・基本的な1命令1データ処理。逐次実行が基本<br/>・命令とデータが1:1で対応し、シンプルな実行モデル<br/>・パイプライン/キャッシュで高速化するが、ハザード検出/回避が必要 |
| ドメイン固有         | ・専用プロセッサ | ・AI/画像/信号処理等の特定用途に特化した専用アーキテクチャ<br/>・汎用性は低いが特定処理で高性能かつ電力効率が良い<br/>・専用コンパイラ/ライブラリが必要だが最適化された処理が可能 |

#### 並列性レベルの階層イメージ
- プロセッサレベル（最も粗い）
  - スレッドレベル
    - 命令レベル（ILP）
      - データレベル（DLP）
        - スカラ（最も細かい）
  
> **高速化の方針の違い**：
> - スカラ：命令パイプラインや分岐予測など「命令の流れ」を効率化して高速化
> - データレベル：同じ命令で「複数データを同時に処理」して高速化

> **階層構造の特徴**：
> - 各レベルは下位の並列性を内包し、複数の階層が組み合わさって高性能な並列処理が実現される
> - 上位レベル（プロセッサレベル）ほど並列処理の基盤となるインフラを提供
>   - マルチコア、SMP/NUMAなどは他の並列性を実現するための「土台」として必須
> - 下位レベルに行くほど特化型の処理に焦点が当てられる
>   - データレベル（SIMD/GPU）やドメイン固有レベルは、特定の処理に特化したアクセラレータとしての役割が強い
>   - 高度に最適化された処理を提供するが、上位レベルのインフラ上で動作することが前提

---
## 4. メモリ構造

### メモリアーキテクチャの分類
- **メモリ階層化** `[単位: メモリレベル]`
- **共有/プライベートメモリ** `[単位: アドレス空間]`

---

## 5. 相互接続ネットワーク

### ネットワーク構成要素
- **ノード/リンク/トポロジ** `[単位: ノード間接続]`

> **トポロジとは**: ノード同士の接続形態。バス、リング、メッシュ、ツリー、N-キューブ（ハイパーキューブ）、全結合、マルチステージ（クロスバ、バタフライなど）などがある。それぞれ通信遅延や拡張性、コストに特徴がある。

### 主要なトポロジタイプ
- **種類**
  - **バス** 
    - 誰かがバスを利用すると他のノードは待たされる.
    - 隣同士と端同士ではかかる時間が異なるかも.
  - **リング**
    - 同時に複数の通信が可能.
  - **全結合網**
    - 全てのコンピュータが1対1でつながる.
    - コスト高い
- **性能評価**
  - **メッセージあたりのレイテンシ(遅延)**
  - **スループット(バンド幅)**

---

## 6. ベンチマーク・性能指標

### 測定対象
- **プログラム/アプリ/システム** `[単位: 測定対象全体]`

### 主要なベンチマーク
- **Linpack**
- **SPEC**

- **ルーフライン（Roofline）モデル**

#### ルーフラインモデルとは
ルーフラインモデルは、計算機システムの性能上限（スループット）を「計算性能」と「メモリ帯域」の2つの観点から可視化するためのグラフモデルです。主にHPC（高性能計算）分野で、アプリケーションやアルゴリズムのボトルネック分析や最適化指針として利用されます。

#### 基本構造
- **横軸**：演算強度（Operational Intensity, OI）
  - 1バイトのデータ転送あたりに実行される浮動小数点演算数（FLOP/Byte）
- **縦軸**：実効性能（FLOPS, 浮動小数点演算/秒）

グラフ上には2つの「天井（Roof）」が描かれます：
1. **メモリ帯域の天井**（斜めの直線）
   - メモリ帯域幅 × OI で決まる。演算強度が低い領域では、性能はメモリ帯域によって制限される。
   - **最適化するには**
     - software,prefetch命令で予測を行う
     - メモリの同じ位置は同じプロセッサで参照する.
2. **計算性能の天井**（水平線）
   - プロセッサの理論最大FLOPS。演算強度が高い領域では、性能は計算能力によって制限される。
   - **最適化するには**
     - 浮動小数点加算と浮動小数点乗算を一緒にすると性能が上がる.
     - スーパースカラの場合,同時に発行できる命令数を増やして性能up.

#### 使い方・読み方
- アプリケーションやカーネルの演算強度を横軸にプロットし、実測性能を縦軸に点で示す。
- 点がどちらの天井に近いかで、ボトルネック（メモリか計算か）が分かる。
- 例えば、点が斜め線（メモリ帯域天井）に近ければ「メモリボトルネック」、水平線（計算天井）に近ければ「計算ボトルネック」。

#### ルーフラインモデルの意義
- **最適化指針**：どちらの天井に近づけるかで、最適化の方向性（メモリアクセスの削減 or 演算効率の向上）が明確になる。

#### 参考図（イメージ）
```text
  ^
  |         ──────────────── 計算性能の天井（水平線）
  |        /
  |       /
  |      /
  |     /
  |    /
  |   /
  |  /
  | /  ← メモリ帯域の天井（斜め線）
  +----------------------------->
    ↑
    演算強度（FLOP/Byte）
```
## 用語解説

### マルチスレッド
複数のスレッド（実行の流れ）を切り替えたり同時に実行したりできる仕組み全般を指す。ソフトウェア（OSやランタイムによるスレッド切替）とハードウェア（CPUによる同時/高速切替）の両方を含む。

ハードウェア的マルチスレッドには以下が含まれる：
- **SMT（同時マルチスレッディング）**
- **粗粒度マルチスレッド**
- **細粒度マルチスレッド**